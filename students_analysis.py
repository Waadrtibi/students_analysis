# ğŸ“¦ Importation des bibliothÃ¨ques nÃ©cessaires
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import streamlit as st
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc
import numpy as np

# âš™ï¸ Configuration de la page Streamlit
st.set_page_config(page_title="Analyse & PrÃ©diction Ã‰tudiants", layout="wide")
st.title("ğŸ“ Analyse & PrÃ©diction des RÃ©sultats des Ã‰tudiants")

# ğŸ“¥ Chargement et prÃ©paration des donnÃ©es avec mise en cache pour optimiser les performances
@st.cache_data  # UtilisÃ© pour ne pas recharger les donnÃ©es Ã  chaque interaction
def load_data():
    # Lecture du fichier CSV contenant les donnÃ©es
    df = pd.read_csv("C:/Users/Waad RTIBI/students_analysis/StudentsPerformance.csv")

    # Calcul de la moyenne des scores
    df["average_score"] = df[["math score", "reading score", "writing score"]].mean(axis=1)

    # CrÃ©ation de la colonne 'passed' : 1 si la moyenne >= 60, sinon 0
    df["passed"] = df["average_score"].apply(lambda x: 1 if x >= 60 else 0)
    return df

# ğŸ“Š Chargement des donnÃ©es
df = load_data()

# ğŸ§  Encodage des variables catÃ©gorielles pour les rendre exploitables par les modÃ¨les
df_encoded = pd.get_dummies(df, columns=["gender", "test preparation course"], drop_first=True)

# ğŸ§® SÃ©lection des caractÃ©ristiques pertinentes pour l'entraÃ®nement
features = ["math score", "reading score", "writing score", "gender_male", "test preparation course_none"]
X = df_encoded[features]  # Variables explicatives
y = df_encoded["passed"]  # Variable cible

# âš–ï¸ Normalisation des donnÃ©es
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ğŸ”€ SÃ©paration des donnÃ©es en jeu d'entraÃ®nement et de test
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# ğŸ¤– DÃ©finition des modÃ¨les de machine learning Ã  tester
models = {
    "Logistic Regression": LogisticRegression(),
    "Random Forest": RandomForestClassifier(random_state=42),
    "K-Nearest Neighbors": KNeighborsClassifier()
}

# ğŸ›ï¸ Barre latÃ©rale pour sÃ©lectionner un modÃ¨le
st.sidebar.title("ğŸ” Choix du ModÃ¨le")
model_name = st.sidebar.radio("SÃ©lectionnez un modÃ¨le :", list(models.keys()))

# ğŸ§ª EntraÃ®nement et Ã©valuation de chaque modÃ¨le
results = {}
for name, model in models.items():
    model.fit(X_train, y_train)  # EntraÃ®nement
    y_pred = model.predict(X_test)  # PrÃ©dictions
    y_proba = model.predict_proba(X_test)[:, 1]  # ProbabilitÃ©s pour la courbe ROC
    acc = accuracy_score(y_test, y_pred)  # PrÃ©cision
    fpr, tpr, _ = roc_curve(y_test, y_proba)  # Courbe ROC
    results[name] = {
        "model": model,
        "y_pred": y_pred,
        "accuracy": acc,
        "fpr": fpr,
        "tpr": tpr,
        "conf_matrix": confusion_matrix(y_test, y_pred)
    }

# ğŸ“ˆ Affichage des rÃ©sultats du modÃ¨le sÃ©lectionnÃ©
st.header(f"ğŸ“‹ RÃ©sultats pour : {model_name}")
st.write(f"**ğŸ¯ Accuracy** : {results[model_name]['accuracy']:.2f}")

# ğŸ”· Matrice de confusion
fig_cm, ax_cm = plt.subplots()
sns.heatmap(results[model_name]["conf_matrix"], annot=True, fmt="d", cmap="Blues", ax=ax_cm)
ax_cm.set_xlabel("PrÃ©dit")
ax_cm.set_ylabel("RÃ©el")
ax_cm.set_title("Matrice de Confusion")
st.pyplot(fig_cm)

# ğŸ“‰ Courbe ROC comparant tous les modÃ¨les
fig_roc, ax_roc = plt.subplots()
for name, res in results.items():
    ax_roc.plot(res["fpr"], res["tpr"], label=f"{name} (AUC = {auc(res['fpr'], res['tpr']):.2f})")
ax_roc.plot([0, 1], [0, 1], 'k--', label="Random")  # Ligne alÃ©atoire
ax_roc.set_xlabel("Taux de Faux Positifs")
ax_roc.set_ylabel("Taux de Vrais Positifs")
ax_roc.set_title("ğŸ“Š Courbe ROC des ModÃ¨les")
ax_roc.legend(loc="lower right")
st.pyplot(fig_roc)

# ğŸ§¾ Tableau comparatif des performances
st.subheader("ğŸ“Š Comparaison des Performances")
compare_df = pd.DataFrame({
    "ModÃ¨le": list(results.keys()),
    "Accuracy": [results[k]["accuracy"] for k in results]
}).sort_values("Accuracy", ascending=False)

st.dataframe(compare_df)
